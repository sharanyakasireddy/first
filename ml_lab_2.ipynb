{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharanyakasireddy/first/blob/main/ml_lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 A\n"
      ],
      "metadata": {
        "id": "ZZBkMj6CftgV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht7hHy-Ceh4o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"D:\\\\Material\\\\Machine Learning\\\\Programs\\\\Logistic Regression\\\\DigitalAd_dataset.csv\")\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "Y = data.iloc[:, -1].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(cm)\n",
        "print(\"Accuracy of the Model: {0}%\".format(accuracy_score(y_test, y_pred)*100))\n",
        "\n",
        "age = int(input(\"Enter New Customer Age: \"))\n",
        "sal = int(input(\"Enter New Customer Salary: \"))\n",
        "newCust = [[age, sal]]\n",
        "result = model.predict(sc.transform(newCust))\n",
        "print(result)\n",
        "if result == 1:\n",
        "    print(\"Customer will Buy\")\n",
        "else:\n",
        "    print(\"Customer won't Buy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2a"
      ],
      "metadata": {
        "id": "kcaxOzHmUdii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization purposes\n",
        "import seaborn as sns # for statistical data visualization\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv(\"D:\\\\Material\\\\Machine Learning\\\\Programs\\\\Naive Bayesian Classifier\\\\adult.csv\")\n",
        "df.shape\n",
        "df.head()\n",
        "df.info()\n",
        "\n",
        "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
        "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "print('The categorical variables are :\\n\\n', categorical)\n",
        "df[categorical].head()\n",
        "df[categorical].isnull().sum()\n",
        "\n",
        "# view frequency counts of values in categorical variables\n",
        "for var in categorical:\n",
        "    print(df[var].value_counts())\n",
        "\n",
        "# view frequency distribution of categorical variables\n",
        "for var in categorical:\n",
        "    print(df[var].value_counts()/float(len(df)))\n",
        "\n",
        "# check labels in workclass variable\n",
        "df.workclass.unique()\n",
        "\n",
        "# check frequency distribution of values in workclass variable\n",
        "df.workclass.value_counts()\n",
        "\n",
        "# replace '?' values in workclass variable with `NaN`\n",
        "df['workclass'].replace('?', np.NaN, inplace=True)\n",
        "\n",
        "# again check the frequency distribution of values in workclass variable\n",
        "df.workclass.value_counts()\n",
        "\n",
        "# check labels in occupation variable\n",
        "df.occupation.unique()\n",
        "\n",
        "# check frequency distribution of values in occupation variable\n",
        "df.occupation.value_counts()\n",
        "\n",
        "# replace '?' values in occupation variable with `NaN`\n",
        "df['occupation'].replace('?', np.NaN, inplace=True)\n",
        "\n",
        "# again check the frequency distribution of values in occupation variable\n",
        "df.occupation.value_counts()\n",
        "\n",
        "# check labels in native_country variable\n",
        "df.native_country.unique()\n",
        "\n",
        "# check frequency distribution of values in native_country variable\n",
        "df.native_country.value_counts()\n",
        "\n",
        "# replace '?' values in native_country variable with `NaN`\n",
        "df['native_country'].replace('?', np.NaN, inplace=True)\n",
        "\n",
        "# again check the frequency distribution of values in native_country variable\n",
        "df.native_country.value_counts()\n",
        "\n",
        "# Check missing values in categorical variables again\n",
        "df[categorical].isnull().sum()\n",
        "\n",
        "# check for cardinality in categorical variables\n",
        "for var in categorical:\n",
        "    print(var, ' contains ', len(df[var].unique()), ' labels')\n",
        "\n",
        "# find numerical variables\n",
        "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
        "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
        "print('The numerical variables are :', numerical)\n",
        "\n",
        "# view the numerical variables\n",
        "df[numerical].head()\n",
        "\n",
        "# check missing values in numerical variables\n",
        "df[numerical].isnull().sum()\n",
        "\n",
        "X = df.drop(['income'], axis=1)\n",
        "y = df['income']\n",
        "\n",
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# check the shape of X_train and X_test\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# check data types in X_train\n",
        "X_train.dtypes\n",
        "\n",
        "# display categorical variables\n",
        "categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
        "categorical\n",
        "\n",
        "# display numerical variables\n",
        "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
        "numerical\n",
        "\n",
        "# print percentage of missing values in the categorical variables in the training set\n",
        "X_train[categorical].isnull().mean()\n",
        "\n",
        "# print categorical variables with missing data\n",
        "for col in categorical:\n",
        "    if X_train[col].isnull().mean() > 0:\n",
        "        print(col, (X_train[col].isnull().mean()))\n",
        "\n",
        "# impute missing categorical variables with the most frequent value\n",
        "for df2 in [X_train, X_test]:\n",
        "    df2['workclass'].fillna(X_train['workclass'].mode()[0], inplace=True)\n",
        "    df2['occupation'].fillna(X_train['occupation'].mode()[0], inplace=True)\n",
        "    df2['native_country'].fillna(X_train['native_country'].mode()[0], inplace=True)\n",
        "\n",
        "# check missing values in categorical variables in X_train\n",
        "X_train[categorical].isnull().sum()\n",
        "\n",
        "# check missing values in categorical variables in X_test\n",
        "X_test[categorical].isnull().sum()\n",
        "\n",
        "# check missing values in X_train\n",
        "X_train.isnull().sum()\n",
        "\n",
        "# check missing values in X_test\n",
        "X_test.isnull().sum()\n",
        "\n",
        "# print categorical variables\n",
        "categorical\n",
        "X_train[categorical].head()\n",
        "\n",
        "# import category encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "# encode remaining variables with one-hot encoding\n",
        "encoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship',\n",
        "                                 'race', 'sex', 'native_country'])\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "X_train.head()\n",
        "X_train.shape\n",
        "X_test.head()\n",
        "X_test.shape\n",
        "cols = X_train.columns\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train = pd.DataFrame(X_train, columns=[cols])\n",
        "X_test = pd.DataFrame(X_test, columns=[cols])\n",
        "X_train.head()\n",
        "\n",
        "# train a Gaussian Naive Bayes classifier on the training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# instantiate the model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# fit the model\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "GaussianNB(priors=None, var_smoothing=1e-09)\n",
        "\n",
        "y_pred = gnb.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "y_pred_train = gnb.predict(X_train)\n",
        "y_pred_train\n",
        "\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))\n",
        "\n",
        "# print the scores on the training and test set\n",
        "print('Training set score: {:.4f}'.format(gnb.score(X_train, y_train)))\n",
        "print('Test set score: {:.4f}'.format(gnb.score(X_test, y_test)))\n",
        "\n",
        "# check class distribution in the test set\n",
        "y_test.value_counts()\n",
        "\n",
        "# check null accuracy score\n",
        "null_accuracy = (7607/(7607+2392))\n",
        "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "909esl8rQynB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3a"
      ],
      "metadata": {
        "id": "fnzKvHEWUZ-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "def func(x, y):\n",
        "    return -5.5 * tf.exp(-20.0 * (x - 0.3)**2 - 40.0 * (y - 0.3)**2) - 3.5 * tf.exp(-15.0 * (x - 0.6)**2 - 10.0 * (y - 0.85)**2) - 2.0 * tf.sin(2.0 * (x - y))\n",
        "\n",
        "x = np.linspace(0, 1, 400)\n",
        "X, Y = np.meshgrid(x, x)\n",
        "Z = func(X, Y)\n",
        "\n",
        "plt.figure(figsize=(6, 4.7))\n",
        "plt.contourf(X, Y, Z, 60, cmap='RdGy')\n",
        "plt.xlabel('x', fontsize=19)\n",
        "plt.ylabel('y', fontsize=19)\n",
        "plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "cbar = plt.colorbar()\n",
        "cbar.ax.tick_params(labelsize=14)\n",
        "\n",
        "def constr(a, b):\n",
        "    assert b > a\n",
        "    return lambda x: tf.clip_by_value(x, a, b)\n",
        "\n",
        "x = tf.Variable(0.0, trainable=True, dtype=tf.float64, name='x', constraint=constr(0, 1))\n",
        "y = tf.Variable(0.0, trainable=True, dtype=tf.float64, name='y', constraint=constr(0, 1))\n",
        "\n",
        "def objective():\n",
        "    return -5.5 * tf.exp(-20.0 * (x - 0.3)**2 - 40.0 * (y - 0.3)**2) - 3.5 * tf.exp(-15.0 * (x - 0.6)**2 - 10.0 * (y - 0.85)**2) - 2.0 * tf.sin(2.0 * (x - y))\n",
        "\n",
        "def optimize(start, verbose=False, method='SGD'):\n",
        "    x.assign(start[0])\n",
        "    y.assign(start[1])\n",
        "\n",
        "    if method == 'SGD':\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "    elif method == 'ADAM':\n",
        "        opt = tf.keras.optimizers.Adam(\n",
        "            learning_rate=0.1,\n",
        "            beta_1=0.9,\n",
        "            beta_2=0.999,\n",
        "            epsilon=1e-07,\n",
        "            amsgrad=False,\n",
        "        )\n",
        "\n",
        "    obj_vals = []\n",
        "    coords = []\n",
        "\n",
        "    for i in range(50):\n",
        "        if verbose and i % 5 == 0:\n",
        "            print(f'step: {i}, obj = {objective().numpy():.4f}, x = {x.numpy():.4f}, y = {y.numpy():.4f}')\n",
        "        obj_vals.append(objective().numpy())\n",
        "        coords.append((x.numpy(), y.numpy()))\n",
        "        opt.minimize(objective, var_list=[x, y])\n",
        "\n",
        "    return obj_vals, coords\n",
        "\n",
        "def plot_res(obj_vals, coords):\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.subplot(121)\n",
        "    plt.contourf(X, Y, Z, 60, cmap='RdGy')\n",
        "    plt.xlabel('x', fontsize=19)\n",
        "    plt.ylabel('y', fontsize=19)\n",
        "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.ax.tick_params(labelsize=14)\n",
        "\n",
        "    xcoord = [x[0] for x in coords]\n",
        "    ycoord = [x[1] for x in coords]\n",
        "    plt.plot(xcoord, ycoord, '.-')\n",
        "    plt.plot(xcoord[-1], ycoord[-1], \"y*\", markersize=12)\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(obj_vals, '.-')\n",
        "    plt.plot([len(obj_vals) - 1], obj_vals[-1], \"y*\", markersize=12)\n",
        "    plt.xlabel('Step', fontsize=17)\n",
        "    plt.ylabel('Objective', fontsize=17)\n",
        "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "    plt.show()\n",
        "\n",
        "obj_vals, coords = optimize([0.25, 0.65], verbose=True, method='SGD')\n",
        "plot_res(obj_vals, coords)\n",
        "\n",
        "obj_vals, coords = optimize([0.2, 0.65], method='SGD')\n",
        "plot_res(obj_vals, coords)\n",
        "\n",
        "obj_vals, coords = optimize([0.2, 0.65], method='ADAM')\n",
        "plot_res(obj_vals, coords)\n"
      ],
      "metadata": {
        "id": "X_xKRF5DRXoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 a"
      ],
      "metadata": {
        "id": "e1_wBqNEUV8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = pd.read_csv('D:\\\\Material\\\\Machine Learning\\\\Programs\\\\Supervised Learning\\\\Iris.csv')\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.iloc[:, :-1].values    # X -> Feature Variables\n",
        "y = data.iloc[:, -1].values     # y -> Target\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "X_trainL, X_testL, y_trainL, y_testL = train_test_split(X, y_encoded, test_size=0.3, random_state=0)\n",
        "\n",
        "# Linear Regression (For demonstration only)\n",
        "modelLR = LinearRegression()\n",
        "modelLR.fit(X_trainL, y_trainL)\n",
        "Y_pred_LR = modelLR.predict(X_testL)\n",
        "print('Linear Regression Results:')\n",
        "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_testL, Y_pred_LR))\n",
        "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_testL, Y_pred_LR))\n",
        "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_testL, Y_pred_LR)))\n",
        "print('R-squared:', metrics.r2_score(y_testL, Y_pred_LR))\n",
        "\n",
        "# Decision Tree\n",
        "Model_DT = DecisionTreeClassifier()\n",
        "Model_DT.fit(X_train, y_train)\n",
        "y_pred_DT = Model_DT.predict(X_test)\n",
        "print('Decision Tree Results:')\n",
        "print(classification_report(y_test, y_pred_DT))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_DT))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_DT))\n",
        "\n",
        "# Random Forest Classifier\n",
        "Model_RF = RandomForestClassifier(max_depth=2)\n",
        "Model_RF.fit(X_train, y_train)\n",
        "y_pred_RF = Model_RF.predict(X_test)\n",
        "print('Random Forest Classifier Results:')\n",
        "print(classification_report(y_test, y_pred_RF))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_RF))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "# Logistic Regression\n",
        "Model_LR = LogisticRegression()\n",
        "Model_LR.fit(X_train, y_train)\n",
        "y_pred_LR = Model_LR.predict(X_test)\n",
        "print('Logistic Regression Results:')\n",
        "print(classification_report(y_test, y_pred_LR))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_LR))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_LR))\n",
        "\n",
        "# K-Nearest Neighbors\n",
        "Model_KNN = KNeighborsClassifier(n_neighbors=8)\n",
        "Model_KNN.fit(X_train, y_train)\n",
        "y_pred_KNN = Model_KNN.predict(X_test)\n",
        "print('K-Nearest Neighbors Results:')\n",
        "print(classification_report(y_test, y_pred_KNN))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_KNN))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_KNN))\n",
        "\n",
        "# Naive Bayes\n",
        "Model_NB = GaussianNB()\n",
        "Model_NB.fit(X_train, y_train)\n",
        "y_pred_NB = Model_NB.predict(X_test)\n",
        "print('Naive Bayes Results:')\n",
        "print(classification_report(y_test, y_pred_NB))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_NB))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_NB))\n",
        "\n",
        "# Support Vector Machine\n",
        "Model_SVM = SVC()\n",
        "Model_SVM.fit(X_train, y_train)\n",
        "y_pred_SVM = Model_SVM.predict(X_test)\n",
        "print('Support Vector Machine Results:')\n",
        "print(classification_report(y_test, y_pred_SVM))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_SVM))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_SVM))\n"
      ],
      "metadata": {
        "id": "FTRpT65sRu_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "demo of clustering algo"
      ],
      "metadata": {
        "id": "5xmEhDgfUPx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import mglearn\n",
        "df = pd.read_csv(\"D:\\\\Material\\\\Machine Learning\\\\Programs\\\\Clustering\\\\Mall_Customers.csv\")\n",
        "df.head()\n",
        "df.columns = ['customer_ID','gender','age','annual_income','spending_score']\n",
        "df.head()\n",
        "df.shape\n",
        "df.duplicated().any()\n",
        "df.isnull().any()\n",
        "df = df.set_index(['customer_ID'])\n",
        "df.head()\n",
        "X = df.drop(['gender'], axis=1)\n",
        "X.head()\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "clusters = []\n",
        "ss = []\n",
        "#Calculate all the sum of within-cluster variance for n_clusters from 2 to 14\n",
        "for i in range(2,15):\n",
        "    km = KMeans(n_clusters = i)\n",
        "    km.fit(X)\n",
        "    clusters.append(km.inertia_)\n",
        "    ss.append(silhouette_score(X, km.labels_, metric='euclidean'))\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.lineplot(x=list(range(2, 15)), y=clusters, ax=ax)\n",
        "ax.set_title('Searching for Elbow')\n",
        "ax.set_xlabel('Clusters')\n",
        "ax.set_ylabel('Inertia')\n",
        "\n",
        "# Annotate arrow\n",
        "ax.annotate('Possible Elbow Point', xy=(5, 80000), xytext=(5, 150000), xycoords='data',\n",
        "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n",
        "\n",
        "plt.show()\n",
        "km5 = KMeans(n_clusters=5).fit(X)\n",
        "X['Labels'] = km5.labels_\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(121)\n",
        "sns.scatterplot(x=X['annual_income'], y=X['spending_score'], hue=X['Labels'])\n",
        "#,palette=sns.color_palette('hls', 5))\n",
        "ax.set_title('KMeans with 5 Clusters')\n",
        "ax.legend(loc='center right')\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "aggloclus = AgglomerativeClustering(n_clusters=5, linkage='complete').fit(X)\n",
        "\n",
        "labels = aggloclus.labels_\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(121)\n",
        "sns.scatterplot(x=X['annual_income'],y=X['spending_score'], hue=X['Labels'])\n",
        "ax.set_title('Agglomerative 5 clusters with complete linkage')\n",
        "ax.legend(loc='center right')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "dbscan = DBSCAN(eps = 0.7)\n",
        "clusters = dbscan.fit_predict(X_scaled)\n",
        "length = len(np.unique(clusters))\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(121)\n",
        "sns.scatterplot(x=X['annual_income'], y=X['spending_score'], hue=X['Labels'])\n",
        "ax.set_title('DBSCAN with 5 Clusters')\n",
        "ax.legend(loc='center right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xwIcClRaUBmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_Pjs4HJUkGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}